{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import timeit\n",
    "from __main__ import download_tickers, tickers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = pd.read_csv('yfinanceetfs.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = tickers[0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['SBUX']\n",
    "#timeit.timeit(\"stocks = download_tickers(tickers)\", \"from __main__ import download_tickers, tickers\", number=1)\n",
    "stocks = download_tickers(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks2 = stocks.dropna(how='all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "threading.active_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=stocks.loc[:, stocks.columns.get_level_values(1).isin(['Adj Close'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tickers(tickers):\n",
    "    # Fetch downloaded ticker from raw_data\n",
    "    downloaded_tickers = [x[0:-5] if '.pbz2' in x else '' for x in os.listdir('raw_data/')]\n",
    "    downloaded_tickers.remove('')\n",
    "    # Check if tickers already are downloaded\n",
    "    tickers_to_download = []\n",
    "    for ticker in tickers:\n",
    "        if ticker in downloaded_tickers:\n",
    "            # If already downloaded, check if they need updates\n",
    "            if update_ticker(ticker):\n",
    "                tickers_to_download.append(ticker)\n",
    "        else:\n",
    "            tickers_to_download.append(ticker)\n",
    "\n",
    "    download_dump(tickers_to_download)\n",
    "    \n",
    "    # Read tickers from json and return\n",
    "    return load_stocks(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stocks(tickers):\n",
    "    cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "    index = pd.MultiIndex.from_product([tickers, cols], names=['Stock ticker', 'Data type'])\n",
    "    if len(tickers) > 1:\n",
    "        data = pd.concat([decompress_pickle('raw_data/' + x + '.pbz2') for x in tickers], axis=1, sort=True)\n",
    "    else:\n",
    "        data = decompress_pickle('raw_data/' + tickers[0] + '.pbz2')\n",
    "    \n",
    "    data.columns = index\n",
    "    try:\n",
    "        data.index = pd.to_datetime(data.index, unit='ms')\n",
    "    except ValueError:\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ticker(ticker):\n",
    "    last_bday = last_weekday()\n",
    "    newest_date = decompress_pickle('raw_data/' + ticker + '.pbz2').index[-1]\n",
    "    if newest_date == float:\n",
    "        newest_date = dt.datetime.fromtimestamp(newest_date/1000).date()\n",
    "    if newest_date != last_bday:\n",
    "        return True \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dump(tickers):\n",
    "    if tickers != []:\n",
    "        data = yf.download(tickers, period='100y', group_by='tickers')\n",
    "        if len(tickers) > 1:\n",
    "            for ticker in tickers:\n",
    "                    clean_data = clean_df(data[ticker])\n",
    "                    #clean_data.to_json('raw_data/' + ticker + '.json', date_format='epoch', date_unit='ms')\n",
    "                    compressed_pickle(ticker, clean_data[ticker])\n",
    "        else:\n",
    "            clean_data = clean_df(data)\n",
    "            #clean_data.to_json('raw_data/' + tickers[0] + '.json', date_format='epoch', date_unit='ms')\n",
    "            compressed_pickle(tickers[0], clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_weekday():\n",
    "    todays_day = dt.date.today().day\n",
    "    if todays_day in [5, 6]:\n",
    "        return dt.date.today() - dt.timedelta(days=todays_day-4)\n",
    "    else:\n",
    "        return dt.date.today()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df.dropna(axis = 0, how='all')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressed_pickle(ticker, data):\n",
    "    with bz2.BZ2File('raw_data/' + ticker + '.pbz2', 'w') as f: \n",
    "        cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_pickle(file):\n",
    "    data = bz2.BZ2File(file, 'rb')\n",
    "    data = cPickle.load(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = decompress_pickle('raw_data/AAPL.pbz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_empties():\n",
    "    for filename in os.listdir('raw_data'):\n",
    "        if filename.endswith(\".pbz2\"): \n",
    "            df = pd.DataFrame(decompress_pickle('raw_data/' + filename))\n",
    "            non_zeroes = len(df) - df.iloc[:, 4].isna().sum()\n",
    "            if non_zeroes < 2:\n",
    "                os.remove('raw_data/' + filename)\n",
    "            else:\n",
    "                df = df.dropna(how='all', axis=0)\n",
    "                ticker = filename.replace('.pbz2', '')\n",
    "                compressed_pickle(ticker, df)\n",
    "                \n",
    "                \n",
    "            \n",
    "remove_empties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_rows():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
